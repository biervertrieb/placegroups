{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "providing ../data/raw/2022_place_canvas_history-000000000077.csv ...\n",
      "not found. need to download ../data/raw/2022_place_canvas_history-000000000077.csv.gzip ...\n",
      "downloading from https://placedata.reddit.com/data/canvas-history/2022_place_canvas_history-000000000077.csv.gzip to ../data/raw/2022_place_canvas_history-000000000077.csv.gzip\n",
      "unpacking ../data/raw/2022_place_canvas_history-000000000077.csv.gzip into ../data/raw/2022_place_canvas_history-000000000077.csv\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Compressed file ended before the end-of-stream marker was reached",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/placegroups/notebooks/0.5-heuer-TestZensur.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f55736572732f6e69636f6c65646572722f446f63756d656e74732f4769744875622f706c61636567726f757073/workspaces/placegroups/notebooks/0.5-heuer-TestZensur.ipynb#ch0000000vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m get_dataframei_onlymods\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B2f55736572732f6e69636f6c65646572722f446f63756d656e74732f4769744875622f706c61636567726f757073/workspaces/placegroups/notebooks/0.5-heuer-TestZensur.ipynb#ch0000000vscode-remote?line=2'>3</a>\u001b[0m modframe \u001b[39m=\u001b[39m get_dataframei_onlymods(\u001b[39m77\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f55736572732f6e69636f6c65646572722f446f63756d656e74732f4769744875622f706c61636567726f757073/workspaces/placegroups/notebooks/0.5-heuer-TestZensur.ipynb#ch0000000vscode-remote?line=4'>5</a>\u001b[0m modframe\u001b[39m.\u001b[39mshow(\u001b[39m5\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/placegroups/src/data/dataset_functions.py:50\u001b[0m, in \u001b[0;36mget_dataframei_onlymods\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_dataframei_onlymods\u001b[39m(i: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m     49\u001b[0m     \u001b[39m''' Provides the Pyspark Dataframe data structure ready to use from specific dataset nr '''\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     provide_rawcsvi(i)\n\u001b[1;32m     51\u001b[0m     new_dataframe \u001b[39m=\u001b[39m make_dataframe_from_rawcsvi(i)\n\u001b[1;32m     52\u001b[0m     transformed_dataframe \u001b[39m=\u001b[39m transform_dataframe_onlymods(new_dataframe)\n",
      "File \u001b[0;32m/workspaces/placegroups/src/data/dataset_functions.py:71\u001b[0m, in \u001b[0;36mprovide_rawcsvi\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(filename_csv(i)) \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnot found. need to download \u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mfilename_gzip(i)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m ...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m     provide_and_unpack_gzip(i)\n\u001b[1;32m     72\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[39mprint\u001b[39m(filename_csv(i)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is already in data/raw\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/placegroups/src/data/dataset_functions.py:115\u001b[0m, in \u001b[0;36mprovide_and_unpack_gzip\u001b[0;34m(file_nr)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(gz_name) \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     download_dataset_fromsource(file_nr)\n\u001b[0;32m--> 115\u001b[0m unpack_gzip(file_nr)\n",
      "File \u001b[0;32m/workspaces/placegroups/src/data/dataset_functions.py:180\u001b[0m, in \u001b[0;36munpack_gzip\u001b[0;34m(file_nr)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mwith\u001b[39;00m gzip\u001b[39m.\u001b[39mopen(gz_name, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f_in:\n\u001b[1;32m    179\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(csv_name, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f_out:\n\u001b[0;32m--> 180\u001b[0m         shutil\u001b[39m.\u001b[39;49mcopyfileobj(f_in, f_out)\n\u001b[1;32m    181\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdeleting \u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mgz_name)\n\u001b[1;32m    182\u001b[0m os\u001b[39m.\u001b[39mremove(gz_name)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/shutil.py:205\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    203\u001b[0m fdst_write \u001b[39m=\u001b[39m fdst\u001b[39m.\u001b[39mwrite\n\u001b[1;32m    204\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     buf \u001b[39m=\u001b[39m fsrc_read(length)\n\u001b[1;32m    206\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m buf:\n\u001b[1;32m    207\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/gzip.py:300\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39merrno\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(errno\u001b[39m.\u001b[39mEBADF, \u001b[39m\"\u001b[39m\u001b[39mread() on write-only GzipFile object\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 300\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer\u001b[39m.\u001b[39;49mread(size)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadinto\u001b[39m(\u001b[39mself\u001b[39m, b):\n\u001b[1;32m     67\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b) \u001b[39mas\u001b[39;00m view, view\u001b[39m.\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m byte_view:\n\u001b[0;32m---> 68\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m(byte_view))\n\u001b[1;32m     69\u001b[0m         byte_view[:\u001b[39mlen\u001b[39m(data)] \u001b[39m=\u001b[39m data\n\u001b[1;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/gzip.py:506\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     \u001b[39mif\u001b[39;00m buf \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 506\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCompressed file ended before the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    507\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mend-of-stream marker was reached\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_read_data( uncompress )\n\u001b[1;32m    510\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pos \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(uncompress)\n",
      "\u001b[0;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
     ]
    }
   ],
   "source": [
    "from src.data.dataset_functions import get_dataframei_onlymods\n",
    "\n",
    "modframe = get_dataframei_onlymods(77)\n",
    "\n",
    "modframe.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "providing ../data/raw/2022_place_canvas_history-000000000017.csv ...\n",
      "not found. need to download ../data/raw/2022_place_canvas_history-000000000017.csv.gzip ...\n",
      "downloading from https://placedata.reddit.com/data/canvas-history/2022_place_canvas_history-000000000017.csv.gzip to ../data/raw/2022_place_canvas_history-000000000017.csv.gzip\n",
      "unpacking ../data/raw/2022_place_canvas_history-000000000017.csv.gzip into ../data/raw/2022_place_canvas_history-000000000017.csv\n",
      "deleting ../data/raw/2022_place_canvas_history-000000000017.csv.gzip\n",
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/vscode/.ivy2/cache\n",
      "The jars for the packages stored in: /home/vscode/.ivy2/jars\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f8dcd80f-dd19-44cb-b899-e6df01a7169a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.16 in central\n",
      ":: resolution report :: resolve 71ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\tgraphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.16 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f8dcd80f-dd19-44cb-b899-e6df01a7169a\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/3ms)\n",
      "22/07/05 18:09:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+---+---+---+-----------+\n",
      "|user_id| x1| y1| x2| y2|  t|pixel_color|\n",
      "+-------+---+---+---+---+---+-----------+\n",
      "+-------+---+---+---+---+---+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from src.data.dataset_functions import get_dataframe_onlymods_full\n",
    "\n",
    "mods = get_dataframe_onlymods_full(True)\n",
    "mods.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na dann gucken wir mal was bei (271,1835)-(296,1859) zum Zeitpunkt 562 übermalt wurde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "providing ../data/raw/2022_place_canvas_history-000000000012.csv ...\n",
      "../data/raw/2022_place_canvas_history-000000000012.csv is already in data/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from src.data.dataset_functions import get_dataframei\n",
    "\n",
    "dataFrame = get_dataframei(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_x = 871\n",
    "max_x = 878\n",
    "min_y = 546\n",
    "max_y = 550\n",
    "tz = 151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.feature_functions import get_latestpixels_from_box\n",
    "\n",
    "censoredData = get_latestpixels_from_box(dataFrame,min_x,min_y,max_x,max_y,tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+---+-----------+\n",
      "|  x|  y|user_id|  t|pixel_color|\n",
      "+---+---+-------+---+-----------+\n",
      "+---+---+-------+---+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censoredData.show(5)\n",
    "censoredData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Koordinaten normalisieren..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------------------+---+-----------+\n",
      "|  x|  y|             user_id|  t|pixel_color|\n",
      "+---+---+--------------------+---+-----------+\n",
      "|  1| 24|z90rX9xnUC9Tfb/T7...|359|    #000000|\n",
      "|  2| 18|GuF+xzrhhROmfacr6...|147|    #FF4500|\n",
      "|  3| 17|HHV4dR8dNHXWZsQjL...| 27|    #FF4500|\n",
      "|  3| 22|I35ca7LfMboIZJhOz...|328|    #FF99AA|\n",
      "|  4|  8|L1axPsUn4/6uJMpN3...|556|    #FFF8B8|\n",
      "+---+---+--------------------+---+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "censoredData = censoredData.withColumn('x' , censoredData['x'] - min_x).withColumn('y', censoredData['y'] - min_y)\n",
    "censoredData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "len_x = max_x-min_x+1\n",
    "print(len_x)\n",
    "len_y = max_y-min_y+1\n",
    "print(len_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_rbg(hexcolor):\n",
    "    hexcolor = hexcolor.lstrip('#')\n",
    "    lv = len(hexcolor)\n",
    "    return [int(hexcolor[i:i + lv // 3], 16) for i in range(0, lv, lv // 3)]\n",
    "\n",
    "def hex_to_float(hexcolor):\n",
    "    hexcolor = hexcolor.lstrip('#')\n",
    "    lv = len(hexcolor)\n",
    "    return [int(hexcolor[i:i + lv // 3], 16) / 255.0 for i in range(0, lv, lv // 3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = np.zeros([len_x,len_y,3])\n",
    "\n",
    "collectedData = censoredData.collect()\n",
    "\n",
    "for row in collectedData:\n",
    "    xs , ys , user_id , ts , hexcolor = list(row)\n",
    "    data[xs][ys] = hex_to_float(hexcolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpimg.imsave(\"test.jpg\",data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
