{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "providing ../data/raw/2022_place_canvas_history-000000000077.csv ...\n",
      "not found. need to download ../data/raw/2022_place_canvas_history-000000000077.csv.gzip ...\n",
      "downloading from https://placedata.reddit.com/data/canvas-history/2022_place_canvas_history-000000000077.csv.gzip to ../data/raw/2022_place_canvas_history-000000000077.csv.gzip\n",
      "unpacking ../data/raw/2022_place_canvas_history-000000000077.csv.gzip into ../data/raw/2022_place_canvas_history-000000000077.csv\n",
      "deleting ../data/raw/2022_place_canvas_history-000000000077.csv.gzip\n",
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/vscode/.ivy2/cache\n",
      "The jars for the packages stored in: /home/vscode/.ivy2/jars\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7d50cfdf-8817-4fb0-bfb6-606812d6fbc7;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.16 in central\n",
      ":: resolution report :: resolve 77ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\tgraphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.16 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7d50cfdf-8817-4fb0-bfb6-606812d6fbc7\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/3ms)\n",
      "22/07/08 12:29:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "[Stage 2:>                                                          (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+---+---+---+-----------+\n",
      "|user_id| x1| y1| x2| y2|  t|pixel_color|\n",
      "+-------+---+---+---+---+---+-----------+\n",
      "+-------+---+---+---+---+---+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from src.data.dataset_functions import get_dataframei_onlymods\n",
    "\n",
    "modframe = get_dataframei_onlymods(77)\n",
    "\n",
    "modframe.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "providing ../data/raw/2022_place_canvas_history-000000000017.csv ...\n",
      "not found. need to download ../data/raw/2022_place_canvas_history-000000000017.csv.gzip ...\n",
      "downloading from https://placedata.reddit.com/data/canvas-history/2022_place_canvas_history-000000000017.csv.gzip to ../data/raw/2022_place_canvas_history-000000000017.csv.gzip\n",
      "unpacking ../data/raw/2022_place_canvas_history-000000000017.csv.gzip into ../data/raw/2022_place_canvas_history-000000000017.csv\n",
      "deleting ../data/raw/2022_place_canvas_history-000000000017.csv.gzip\n",
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/vscode/.ivy2/cache\n",
      "The jars for the packages stored in: /home/vscode/.ivy2/jars\n",
      "graphframes#graphframes added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f8dcd80f-dd19-44cb-b899-e6df01a7169a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound graphframes#graphframes;0.8.2-spark3.2-s_2.12 in spark-packages\n",
      "\tfound org.slf4j#slf4j-api;1.7.16 in central\n",
      ":: resolution report :: resolve 71ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\tgraphframes#graphframes;0.8.2-spark3.2-s_2.12 from spark-packages in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.16 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f8dcd80f-dd19-44cb-b899-e6df01a7169a\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/3ms)\n",
      "22/07/05 18:09:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+---+---+---+-----------+\n",
      "|user_id| x1| y1| x2| y2|  t|pixel_color|\n",
      "+-------+---+---+---+---+---+-----------+\n",
      "+-------+---+---+---+---+---+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from src.data.dataset_functions import get_dataframe_onlymods_full\n",
    "\n",
    "mods = get_dataframe_onlymods_full(True)\n",
    "mods.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na dann gucken wir mal was bei (271,1835)-(296,1859) zum Zeitpunkt 562 Ã¼bermalt wurde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "providing ../data/raw/2022_place_canvas_history-000000000012.csv ...\n",
      "../data/raw/2022_place_canvas_history-000000000012.csv is already in data/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from src.data.dataset_functions import get_dataframei\n",
    "\n",
    "dataFrame = get_dataframei(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_x = 871\n",
    "max_x = 878\n",
    "min_y = 546\n",
    "max_y = 550\n",
    "tz = 151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.feature_functions import get_latestpixels_from_box\n",
    "\n",
    "censoredData = get_latestpixels_from_box(dataFrame,min_x,min_y,max_x,max_y,tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+---+-----------+\n",
      "|  x|  y|user_id|  t|pixel_color|\n",
      "+---+---+-------+---+-----------+\n",
      "+---+---+-------+---+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censoredData.show(5)\n",
    "censoredData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Koordinaten normalisieren..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------------------+---+-----------+\n",
      "|  x|  y|             user_id|  t|pixel_color|\n",
      "+---+---+--------------------+---+-----------+\n",
      "|  1| 24|z90rX9xnUC9Tfb/T7...|359|    #000000|\n",
      "|  2| 18|GuF+xzrhhROmfacr6...|147|    #FF4500|\n",
      "|  3| 17|HHV4dR8dNHXWZsQjL...| 27|    #FF4500|\n",
      "|  3| 22|I35ca7LfMboIZJhOz...|328|    #FF99AA|\n",
      "|  4|  8|L1axPsUn4/6uJMpN3...|556|    #FFF8B8|\n",
      "+---+---+--------------------+---+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "censoredData = censoredData.withColumn('x' , censoredData['x'] - min_x).withColumn('y', censoredData['y'] - min_y)\n",
    "censoredData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "len_x = max_x-min_x+1\n",
    "print(len_x)\n",
    "len_y = max_y-min_y+1\n",
    "print(len_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_rbg(hexcolor):\n",
    "    hexcolor = hexcolor.lstrip('#')\n",
    "    lv = len(hexcolor)\n",
    "    return [int(hexcolor[i:i + lv // 3], 16) for i in range(0, lv, lv // 3)]\n",
    "\n",
    "def hex_to_float(hexcolor):\n",
    "    hexcolor = hexcolor.lstrip('#')\n",
    "    lv = len(hexcolor)\n",
    "    return [int(hexcolor[i:i + lv // 3], 16) / 255.0 for i in range(0, lv, lv // 3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = np.zeros([len_x,len_y,3])\n",
    "\n",
    "collectedData = censoredData.collect()\n",
    "\n",
    "for row in collectedData:\n",
    "    xs , ys , user_id , ts , hexcolor = list(row)\n",
    "    data[xs][ys] = hex_to_float(hexcolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpimg.imsave(\"test.jpg\",data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
